# 系统设计

#### 秒杀系统
##### 一、端上的请求拦截（浏览器/APP）想必春节大家都玩过微信的摇一摇抢红包，用户每摇一次，真的就会往后端发送一次请求么？   
回顾抢票的场景，用户点击“查询”按钮之后，系统卡顿，用户着急，会不自觉的再去频繁点击“查询”，不但没用，反而平白无故增加系统负载，平均一个用户点5次，80%的请求是这么多出来的。   
JS层面，可以限制用户在x秒之内只能提交一次请求，从而降低系统负载。    
画外音：频繁提交，可以友好提示“频率过快”。
APP层面，可以做类似的事情，虽然用户疯狂的在摇微信抢红包，但其实x秒才向后端发起一次请求。    
画外音：这就是所谓的“将请求尽量拦截在系统上游”，浏览器/APP层就能拦截80%+的请求。   


不过，端上的拦截只能挡住普通用户（99%的用户是普通用户），程序员firebug一抓包，写个for循环直接调用后端http接口，js拦截根本不起作用，这下怎么办？     
##### 二、站点层的请求拦截如何抗住程序员写for循环调用http接口，首先要确定用户的唯一标识，对于频繁访问的用户予以拦截。   
用什么来做用户的唯一标识？ip？cookie-id？别想得太复杂，购票类业务都需要登录，用uid就能标识用户。   
在站点层，对同一个uid的请求进行计数和限速，例如：一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。
一个uid，5s只透过一个请求，其余的请求怎么办？
缓存，页面缓存，5秒内到达站点层的其他请求，均返回上次返回的页面。
画外音：车次查询和余票查询都能够这么做，既能保证用户体验（至少没有返回404页面），又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）。 


OK，通过计数、限速、页面缓存拦住了99%的普通程序员，但仍有些高端程序员，例如黑客，控制了10w个肉鸡，手里有10w个uid，同时发请求，这下怎么办？ 
##### 三、服务层的请求拦截并发的请求已经到了服务层，如何进拦截？   
服务层非常清楚业务的库存，非常清楚数据库的抗压能力，可以根据这两者进行削峰限速。    
例如，业务服务很清楚的知道，一列火车只有2000张车票，此时透传10w个请求去数据库，是没有意义的。画外音：假如数据库每秒只能抗500个写请求，就只透传500个。   
用什么削峰？请求队列。 对于写请求，做请求队列，每次只透传有限的写请求去数据层（下订单，支付这样的写业务）。    
只有2000张火车票，即使10w个请求过来，也只透传2000个去访问数据库：        
•	如果前一批请求均成功，再放下一批    
•	如果前一批请求库存已经不足，则后续请求全部返回“已售罄”    
 对于读请求，怎么优化？cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。       
 画外音：缓存做水平扩展，很容易线性扩容。   
 如此削峰限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99%的请求被拦住了。 四、数据库层经过前三层的优化：   
•	浏览器拦截了80%请求   
•	站点层拦截了99%请求，并做了页面缓存   
•	服务层根据业务库存，以及数据库抗压能力，做了写请求队列与数据缓存    
你会发现，每次透到数据库层的请求都是可控的。    


#### 排行榜
排行榜数据存sorted set

#### 微信朋友圈

#### 微信群

#### 关注粉丝关系
mysql 三张表 用户表 粉丝表 发布微博表
redis存sorted set 对微博发布内容按create_time倒叙
大v用户不存redis直接查mysql

#### rpc框架设计

#### 缓存设计

#### 抢红包
钱数分配问题，至少0.01元
数据库减钱问题，不能超减


#### 打车软件和人匹配

