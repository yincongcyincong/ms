# redis

#### redis多线程   
redis6.0收发数据包是多线程，执行命令还是单线程的    

#### 使用redis有哪些好处   
(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)    
(2) 支持丰富数据类型，支持string，list，set，sorted set，hash    
(3) 单线程，事务只支持隔离性    
(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除   

#### redis常见性能问题和解决方案   
(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件   
(2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次   
(3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内   
(4) 尽量避免在压力很大的主库上增加从库   
(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3…   
这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。    

#### MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据
相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略：    
voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰    
volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰   
volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰   
allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰   
allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰   
no-enviction（驱逐）：禁止驱逐数据   

#### Redis 常见的性能问题都有哪些？如何解决？
1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。    
2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。   
3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。    
4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内    


#### redis 最适合的场景
（1）、会话缓存（Session Cache）   
最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？   
幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。   
（2）、全页缓存（FPC）   
除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。    
再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。   
此外，对WordPress的用户来说，Pantheon有一个非常好的插件  wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。   
（3）、队列    
Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。    
（4），排行榜/计数器   
Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：    
当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：   
ZRANGE user_scores 0 10 WITHSCORES    
Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的。   

#### 缓存雪崩
指的是大量缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。   
解决办法    
1.	这个没有完美解决办法，但可以分析用户行为，尽量让失效时间点均匀分布，设置不同的过期时间。    
2.	用加分布式锁或者分布式队列的方式保证缓存的单线程（进程）写 （eg. redis的 SETNX），从而避免失效时大量的并发请求落到底层存储系统上。在加锁方法内先从缓存中再获取一次(防止另外的线程优先获取锁已经写入了缓存)，没有再查DB写入缓存。 （当然也可以： 在没有获取锁(tryLock)的线程中一直轮询缓存，至超限时）    

#### 缓存击穿
指的是热点key在某个特殊的场景时间内恰好失效了，恰好有大量并发请求过来了，造成DB压力。   
解决办法    
与缓存雪崩的解决方法类似： 用加锁或者队列的方式保证缓存的单线程（进程）写，在加锁方法内先从缓存中再获取一次，没有再查DB写入缓存。     
还有一种比较好用的（针对缓存雪崩与缓存击穿）：   
物理上的缓存是不设置超时时间的（或者超时时间比较长）， 但是在缓存的对象上增加一个属性来标识超时时间（此时间相对小）。 当获取到数据后，校验数据内部的标记时间，判定是否快超时了，如果是，异步发起一个线程（控制好并发）去主动更新该缓存。   

#### 缓存穿透
程序在处理缓存时，一般是先从缓存查询，如果缓存没有这个key获取为null，则会从DB中查询，并设置到缓存中去。    
按这种做法，那查询一个一定不存在的数据值，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。    
解决办法    
1.	最好对于每一个缓存key都有一定的规范约束，这样在程序中对不符合parttern的key 的请求可以拒绝。（但一般key都是通过程序自动生成的）    
2.	将可能出现的缓存key的组合方式的所有数值以hash形式存储在一个很大的bitmap中<布隆过滤器>（需要考虑如何将这个可能出现的数据的hash值之后同步到bitmap中， eg. 后端每次新增一个可能的组合就同步一次，或者 穷举），一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力    
3.	常用： 如果对应在数据库中的数据都不存在，我们将此key对应的value设置为一个默认的值，比如“NULL”，并设置一个缓存的失效时间。当然这个key的时效比正常的时效要小的多    

#### redis主从同步
redis主从同步，开始是全量复制，后面是增量，最新的增量数据会发送给从，增量是主和从各保存一个数据的offset，主还有一个内存缓冲区默认1M，储存最新的增量数据，

当网络中断然后又恢复，从会用offset获取增量数据，如果不在缓冲区中，就会全量复制

#### redis平滑扩容
1 加节点     
2指定该节点需迁移的slot     
3 添加节点从原节点复制数据     
4 client操作这些迁移slot时先路由到旧节点，若数据已经迁移返回asking重定向到新节点     
5 数据迁移完毕更新slot和节点映射表    

#### zset数据放多了有什么影响
1.查询慢，qps降低，    
2.单片存储很高，   
3.放在单个key中容易造成某个节点偏移成热节点，还无法迁移    
跳表时间复杂度：log2 n

#### 2.Redis Cluster
基本运行原理结点状态信息结构Cluster中的每个节点都维护一份在自己看来当前整个集群的状态，去中心化的协议   
主要包括：   
  1.当前集群状态
  2.集群中各节点所负责的slots信息，及其migrate状态   
  3.集群中各节点的master-slave状态   
  4.集群中各节点的存活状态及不可达投票也就是说上面的信息，   
  就是集群中Node相互八卦传播流言蜚语的内容主题，而且比较全面，既有自己的更有别人的，这么一来大家都相互传，最终信息就全面而且准确了，区别于拜占庭帝国问题，信息的可信度很高。     
  基于Gossip协议当集群状态变化时，如新节点加入、slot迁移、节点宕机、slave提升为新Master，我们希望这些变化尽快的被发现，传播到整个集群的所有节点并达成一致。节点之间相互的心跳（PING，PONG，MEET）及其携带的数据是集群状态传播最主要的途径。
  
#### redis热key
读流量巨大，放低一致性要求，更多副本
1.设置频繁访问的数据过期（让缓存持续命中）    
2.加分布式锁（如果缓存不存在，只让一个进程去读 db，有点类似于单例模式的实现，下面是一个从网上找的小 demo）    
3.数据库限流   
#### redis 大key
1. 集群内存使用不均匀    
2. 查询时是单线程导致阻塞
解决：
将整存整取的大对象，分拆为多个小对象。可以尝试将对象分拆成几个key-value， 使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响；

#### redis压缩链表
```
<zlbytes>，该字段固定是一个四字节的无符号整数，用于表示整个压缩链表所占用内存的长度（以字节为单位），这个长度数值是包含这个<zlbytes>本身的。
<ztail>，该字段固定是一个四字节的无符号整数，用于表示在链表中最后一个节点的偏移字节量，借助这个字段，我们不需要遍历整个链表便可以在链表尾部执行Pop操作。
<zllen>，该字段固定是一个两个字节的无符号整数，用于表示链表中节点的个数。但是该字段最多只能表示2^16-2个节点个数；超过这个数量，也就是该字段被设置为2^16-1时， 意味着我们需要遍历整个链表，才可以获取链表中节点真实的数量。
<entry>，该字段表示链表中的一个节点，同一个链表中的节点，其长度大概率是不同的，因此需要特殊的方式来获取节点的长度，具体的内容会在下一个部分详细介绍。
<zlend>，该字段可以被认为是一个特殊的<entry>节点，用作压缩链表的结束标记，只有一个字节，存储着0xFF，一旦我们遍历到这个特殊的标记，便意味着我们完成了对这个压缩链表的遍历。
```
```
typedef struct zlentry {
    unsigned int prevrawlensize;    //记录<prevlen>字段本身的字节长度
    unsigned int prevrawlen;        //记录保存在<prevlen>字段中前序节点的长度
    unsigned int lensize;           //记录<encoding>字段本身所占用的字节长度
    unsigned int len;               //记录当前entry中data数据所占用的长度，可以为0，表示存储在<encoding>中的小整数
    unsigned int headersize;        //记录当前entry中header的长度，等于prevrawlensize + lensize
    unsigned char encoding;         //记录当前entry中数据的编码方式
    unsigned char *p;               //保存指向当前entry起始位置的指针，而这个指针指向的是当前节点的<prevlen>字段
} zlentry;
```
压缩链表主要用在hash键和列表键
#### 字符串
```
struct sdshdr {

    // 记录 buf 数组中已使用字节的数量
    // 等于 SDS 所保存字符串的长度
    int len;

    // 记录 buf 数组中未使用字节的数量
    int free;

    // 字节数组，用于保存字符串
    char buf[];

};
```
#### rdb复制数据完整性
子进程一开始和父进程共享内存数据，并且kernel把所有的页设置成只读，当有写发生时会触发页中断异常，kernel会把出错的页复制一份给子进程，达到复制效果

#### sort set
 sort set用字典和跳表

#### aof
服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_bug缓冲区的末尾。    
服务器通过不停的时间循环来调用flushAppendOnlyFile函数处理aof_buf缓冲区中内容的写入。   
# appendfsync always 每次都从buffer写入
appendfsync everysec 1s写一次
# appendfsync no     缓冲区满了写入
